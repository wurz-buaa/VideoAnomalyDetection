"""Activations for TensorFlow.
Parag K. Mital, Jan 2016."""
import tensorflow as tf


def lrelu(x, leak=0.2, name="lrelu"):
    """Leaky rectifier.

    Parameters
    ----------
    x : Tensor
        The tensor to apply the nonlinearity to.
    leak : float, optional
        Leakage parameter.
    name : str, optional
        Variable scope to use.

    Returns
    -------
    x : Tensor
        Output of the nonlinearity.
    """
    with tf.variable_scope(name):
        f1 = 0.5 * (1 + leak)
        f2 = 0.5 * (1 - leak)
        return f1 * x + f2 * abs(x)

def lrelu_inverse(x, leak=0.2, name="lrelu_inverse"):
    return lrelu(x, leak = 1.0/leak, name=name)